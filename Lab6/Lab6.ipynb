{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('covtype.data', inferSchema = True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "colNames = [\"Elevation\", \"Aspect\", \"Slope\", \n",
    "           \"HorizontalDistanceToHydrology\",\n",
    "           \"VerticalDistanceToHydrology\",\n",
    "           \"HorizontalDistanceToRoadways\",\n",
    "           \"Hillshade9am\", \"HillShadeNoon\", \"HillShade3pm\",\n",
    "           \"HorizontalDistanceToFirePoints\"] + [f\"WildernessArea{i}\" for i in range(4)] + [f\"SoilType{i}\" for i in range(40)]+ [\"CoverType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.toDF(*colNames).withColumn(\"CoverType\", col(\"CoverType\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, HorizontalDistanceToHydrology: int, VerticalDistanceToHydrology: int, HorizontalDistanceToRoadways: int, Hillshade9am: int, HillShadeNoon: int, HillShade3pm: int, HorizontalDistanceToFirePoints: int, WildernessArea0: int, WildernessArea1: int, WildernessArea2: int, WildernessArea3: int, SoilType0: int, SoilType1: int, SoilType2: int, SoilType3: int, SoilType4: int, SoilType5: int, SoilType6: int, SoilType7: int, SoilType8: int, SoilType9: int, SoilType10: int, SoilType11: int, SoilType12: int, SoilType13: int, SoilType14: int, SoilType15: int, SoilType16: int, SoilType17: int, SoilType18: int, SoilType19: int, SoilType20: int, SoilType21: int, SoilType22: int, SoilType23: int, SoilType24: int, SoilType25: int, SoilType26: int, SoilType27: int, SoilType28: int, SoilType29: int, SoilType30: int, SoilType31: int, SoilType32: int, SoilType33: int, SoilType34: int, SoilType35: int, SoilType36: int, SoilType37: int, SoilType38: int, SoilType39: int, CoverType: double]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData, testData = data.randomSplit([0.9,0.1])\n",
    "trainData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "inputCols = colNames[:-1]\n",
    "vectorAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"featureVector\")\n",
    "assembledTrainData = vectorAssembler.transform(trainData)\n",
    "assembledTestData = vectorAssembler.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(seed = 1, labelCol=\"CoverType\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "model = classifier.fit(assembledTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828906602311283"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(assembledTestData)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol =\"CoverType\", predictionCol=\"prediction\")\n",
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+----+---+---+---+---+\n",
      "|CoverType|    1|    2|   3|  4|  5|  6|  7|\n",
      "+---------+-----+-----+----+---+---+---+---+\n",
      "|      1.0|14734| 5892|  27|  1|  0|  0|360|\n",
      "|      2.0| 5729|21874| 539| 16|  8|  0| 53|\n",
      "|      3.0|    0|  566|3041| 79|  0|  0|  0|\n",
      "|      4.0|    0|    0| 172|100|  0|  0|  0|\n",
      "|      5.0|    3|  858|  67|  0| 12|  0|  0|\n",
      "|      6.0|    0|  593|1107| 70|  0|  0|  0|\n",
      "|      7.0| 1183|   18|   7|  0|  0|  0|888|\n",
      "+---------+-----+-----+----+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusionMatrix = predictions.groupBy(\"CoverType\").pivot(\"prediction\", range(1,8)).count().na.fill(0.0).orderBy(\"CoverType\")\n",
    "confusionMatrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
